{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZxAVG0KDdaBaEbkEAA7Jl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vandana10/rag-app/blob/main/rag_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from PyPDF2 import PdfReader\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def load_file(file_path: str) -> str:\n",
        "    text = \"\"\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "\n",
        "    if ext == \".txt\":\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "    elif ext == \".pdf\":\n",
        "        reader = PdfReader(file_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"  # extract text page by page\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
        "\n",
        "    return text\n",
        "\n",
        "# --------- RAG pipeline ----------\n",
        "def build_qa(file_path: str, api_key: str):\n",
        "    # Load the document\n",
        "    docs = load_file(file_path)\n",
        "\n",
        "    # Split into chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    chunks = splitter.split_text(docs)\n",
        "\n",
        "    # Create embeddings\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "\n",
        "    # Store in FAISS\n",
        "    vectorstore = FAISS.from_texts(chunks, embedding=embeddings)\n",
        "\n",
        "    # Setup LLM\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, openai_api_key=api_key)\n",
        "\n",
        "    # Create RetrievalQA chain\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "load_dotenv()\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "uploaded = files.upload()\n",
        "file_path = \"/content/TestFile.txt\"\n",
        "qa = build_qa(file_path, api_key)\n",
        "query = \"Summarize the document in 3 bullet points.\"\n",
        "response = qa.invoke({\"query\": query})\n",
        "print(\"Answer:\", response[\"result\"])\n",
        "print(\"\\nSource chunks used:\")\n",
        "for doc in response[\"source_documents\"]:\n",
        "      print(\"-\", doc.page_content[:200], \"...\")"
      ],
      "metadata": {
        "id": "9S5fG45D2Oub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQmkmKss_-CA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}